[basic_config]
    # The model name. Default: model
    #model_name =

    # The model path (required). It must be an Onnx model
    model_path =

    # The path that will contain the final partitioning. Default: ksp_result
    #export_directory =

    # Set the path for a temporary directory. Default: tmp
    #temporary_directory =

    # If pybind is used, python needs to access onnx_tool and the dependencies of both onnx_tool and aMMLibrary. If it
    # is set, it will insert in the python path also these paths. The paths must be space separated and the overall
    # string must be put between quotes, e.g. 'path/to/first/location path/to/second/location'.
    #extra_packages_location =



    # The input of the model is firstly available on this device. Default: 0
    #starting_device_id =

    # The output of the model is expected on this device. Default: 0
    #ending_device_id =

    # Set to true if the bandwidth should be used to determine which connections are allowed. Default: false
    use_bandwidth_to_manage_connections =



    # It specifies how bottleneck module should be dealt with: input (add the input layer to the same block node as the
    # bottleneck module), output (add the output layer to the same block node as the bottleneck module) and classic
    # (the input and the output layer will not be added to the same block node as the bottleneck layer). (Required)
    block_graph_mode =

    # The number of repartitioning Network Butcher will try to find. Default: 100
    #K =

    # The K-shortest path method used: eppstein or lazy_eppstein. Default: lazy_eppstein
    #method =

    # Set to true if the memory constraint should be applied. It can be applied if a connection from device id i to
    # device id j is allowed only if i <= j. If the condition is violated, it will ignore the constraint. Default: false
    #memory_constraint =

    # The number of available devices. Default: 1
    #num_devices =


[weight_config]
    # It specifies the chosen weight import mode. Set to either: single_direct_read, multiple_direct_read,
    # block_single_direct_read, block_multiple_direct_read, aMLLibrary_block (case insensitive)
    # Single modes refer to single CSV files, while Multiple will read the files from the various devices.
    # Direct_read will import the weights in the original graph, while Block direct_read will import the weights in the
    # block graph. aMLLibrary_block will generate and import the weights in the block_graph
    import_mode =

    # If single_direct_read or block_single_direct_read, it will specify the CSV file path
    #single_weight_import_path =

    # If single_direct_read or block_single_direct_read, it will specify the relevant columns of the CSV. The order of
    # the columns must match the order of the devices (i.e. from 0 to num_devices-1). The columns must be separated by
    # a space and the resulting string must be put between quotes, e.g. 'firstWeight secondWeight' (case insensitive).
    #single_csv_columns_weights =

    # The separator in the CSV file. Default: ,
    #separator =

    # If aMLLibrary_block is used, it specifies the inference variables of the various models. They must be space
    # separated and the resulting string must be put between quotes, e.g. 'pred pred'.
    #aMLLibrary_inference_variables =

    # If aMLLibrary_block is used, it specifies the collection of features used by both  pickle models to perform the
    # prediction. The features must be space separated and the resulting string must be put between quotes,
    # e.g. 'tensorLength MACs' (available features: tensorLength, networkingTime, NrParameters, NrNodes, Memory, MACs)
    #aMLLibrary_features =



# This set of parameters will store the information about the bandwidth between the various devices
[bandwidth]
    # It stores both the bandwidth and the access time for the communication from device i to device j. i and j must be
    # indices of existing devices.
    # If a pair is not specified and use_bandwidth_to_manage_connections is set to false, it will throw an error if a
    # missing pair is detected.
    # If a pair is not specified and use_bandwidth_to_manage_connections is to true, then a missing pair will be treated
    # as bandwidth = 0 (i.e., no connection from i to j is allowed).
    # As before, the bandwidth and the access time should be separated by a space and quoted, e.g. '10.5 0.005'.
    # [bandwidth] = MBit / s, [access time] = s
    from_i_to_j =



# This set of parameters will store the information about the bandwidth between the various devices only for the
# connection between the input padding node and its out neighbours.
# If it is specified, it overwrites bandwidth. Otherwise, it will default to bandwidth (with the same behaviour).
# Useful if a connection is not allowed "between" the real layers, but it is allowed to send the model input.
[in_bandwidth]
    # Same rules as for bandwidth.
    from_i_to_j =



# This set of parameters will store the information about the bandwidth between the various devices only for the
# connection between the output padding node and its in neighbours.
# If it is specified, it overwrites bandwidth. Otherwise, it will default to bandwidth (with the same behaviour).
# Useful if a connection is not allowed "between" the real layers, but it is allowed to send the model input.
[out_bandwidth]
    # Same rules as for bandwidth.
    from_i_to_j =



# Every device should be inserted as a new entry. The format should be 'device_i' where i is an index starting from 0.
# The indices should be contiguous, e.g. 0,1,2 is allowed, but 1,2,3 is not.
[device_0]
    # Device name. Default: ""
    #name =

    # The maximum memory reserved for the execution of the partitions on the device (in MB). Used only if memory
    # constraint is enabled. Default: 0
    #maximum_memory =

    # If allowed by the weight_config/import_mode, it specifies either the CSV containing the weights or the path to
    # the pickled model to be used with aMLLibrary
    #path =

    # If allowed by the weight_config/import_mode, it specifies the column name of the CSV file containing the weights
    #relevant_entry =